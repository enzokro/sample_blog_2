[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "LLM Class Blog",
    "section": "",
    "text": "Landing page"
  },
  {
    "objectID": "blog/posts/2023-09-27-Blog-Intro/index.html",
    "href": "blog/posts/2023-09-27-Blog-Intro/index.html",
    "title": "nbdev for Blogging and Building Python Libraries",
    "section": "",
    "text": "Create a blog and publish our first post.\n\nBuild a custom, dynamic python library for the Sentiment Analysis pipeline in 01_first_runs.ipynb."
  },
  {
    "objectID": "blog/posts/2023-09-27-Blog-Intro/index.html#goals",
    "href": "blog/posts/2023-09-27-Blog-Intro/index.html#goals",
    "title": "nbdev for Blogging and Building Python Libraries",
    "section": "",
    "text": "Create a blog and publish our first post.\n\nBuild a custom, dynamic python library for the Sentiment Analysis pipeline in 01_first_runs.ipynb."
  },
  {
    "objectID": "blog/posts/2023-09-27-Blog-Intro/index.html#intro",
    "href": "blog/posts/2023-09-27-Blog-Intro/index.html#intro",
    "title": "nbdev for Blogging and Building Python Libraries",
    "section": "Intro:",
    "text": "Intro:\nThis Notebook takes a closer look at the nbdev library. nbdev is a powerful tool built around two main ideas:\n- Literate Programming.\n- Exploratory Programming.\nThe next section gives an overview of these ideas and what makes their combination so powerful.\n\nLiterate Programming\nIn Literate Programming, descriptions (aka documentation) are woven directly into a projectâ€™s source code. This is opposite from most codebases where documentation lives as a separate set of files. It also goes beyond tools like sphinx that instead parse comments and docstrings into documentation.\nCode, tests, and documentation are all first-class citizens in Literate Programming. In nbdev a Notebook is the single, unified source for all three of these things. Instead of having to independently manage code, docs, and tests, everything happens in the Notebook. If the Notebook runs then you know your code will run. The tight integration between what youâ€™re doing (code), describing what youâ€™re doing (documentation), and making sure itâ€™s correct (tests) is a great approach for both research and thinking in general.\n\n\nExploratory Programming\nExploratory Programming is an open-ended approach for new problems and unknown domains. Itâ€™s very helpful at the start of a project before its scope or requirements are fully flushed out.\nThe interactive and dynamic nature of Notebooks is ideal for Exploratory Programming. It makes the barrier to try new things extremely low. And itâ€™s fun! Jupyter also has many extra tools to inspect code and debug its outputs.\n\n\nCombining Literate and Exploratory Programming\nnbdevâ€™s main workflow combines these two ideas. Itâ€™s a great combo for trying things out, figuring out what they do, and how they work. We can poke around and explore codebases in a much more interactive way than usual. Iterations are fast and cheap so itâ€™s easy to follow any hit of curiosity. And if anything breaks, we can always restart the Notebook and try again!\nWe can also mix and match these ideas as needed. For example at the start of a project, while finding our footing, we might lean Exploratory. Then as the idea matures, we could lean Literate to refine and crystallize our approach.\nNow for our first goal: creating and publishing a blog post."
  },
  {
    "objectID": "blog/posts/2023-09-27-Blog-Intro/index.html#turning-notebooks-into-blog-posts",
    "href": "blog/posts/2023-09-27-Blog-Intro/index.html#turning-notebooks-into-blog-posts",
    "title": "nbdev for Blogging and Building Python Libraries",
    "section": "Turning Notebooks into Blog Posts",
    "text": "Turning Notebooks into Blog Posts\nFirst, a high-level summary of the steps to create the blog.\n\nHigh-Level Steps:\n\nCreate a new nbdev project.\n\nSet up the minimum requirements for an nbdev blog.\n\nPublish the blog to Github pages.\n\n\nNOTE: This section is based on these two references: - Official nbdev tutorial. - Blogging with nbdev.\n\nnbdev leverages an amazing tool called Quarto for blogging. Quarto is a publishing framework tailored to scientific and technical articles and posts. In a way itâ€™s a blogging platform for Literate Programming, where a series of code cells tell a story and take the reader on a journey.\n\n\n\nCreating a new nbdev project\nnbdev works on top of a Git repo, so the step is creating an empty git repository. Here is a handy Github link that takes you straight to the page for creating new repos.\n\nNote: We need a completely empty repo, so donâ€™t include a .gitignore or README.md.\n\nIn this example the empty repo is called sample_blog, but feel free to call it anything youâ€™d like. Weâ€™re not married to this name either, we can always create new repos with different, better names.\nNext, clone this repo to your computer. Make sure to change the github link below to point to your repo instead.\n# clone the repo to your computer\ngit clone https://github.com/enzokro/sample_blog.git # &lt;-- ! link with your repo here\nNow we can move into this empty repo and let nbdev work its initialization magic. Run the nbdev_new command to get started. It will prompt you for some general info like as a short description about your project.\n# move into the new repo and initialize the nbdev project\ncd sample_blog/\nnbdev_new\nAll of the options and configs for your project are found in the settings.ini file. nbdev looks in this file for any info it needs for its commands.\nWhen nbdev_new finishes running, you will have a new nbdev project! Try running a git status command to see everything that was added.\nWe can now commit and push these changes to Github.\n# add, commit, and push the files created by nbdev\ngit add .\ngit commit -m'Initial nbdev project creation'\ngit push\nAs we mentioned earlier, nbdev leverages Quarto for publishing Notebooks. The next steps are turning this nbdev project into a proper Quarto blog.\n\n\nAdding Quarto to the Mix\nStart by activating the virtual environment:\n# acivate the environment\nmamba activate llm_base\nnbdev includes a way to install Quarto using the nbdev_install_quarto command. Go ahead and run it, but note that it will ask you for administrator privileges.\n# install quarto\nnbdev_install_quarto\nYou may need to refresh the terminal session before it can find the quarto commands. To be safe, open up a new terminal and re-activate the environment. Then the command below will check if Quarto was installed successfully.\n# shows us where quarto is installed\nwhich quarto \nNote that the nbs/ folder usually holds the Notebooks that become a projectâ€™s documentation, tests, and source code. To make sure Quarto can publish an nbdev blog we have to add some files and change this directory structure a bit.\nFirst letâ€™s take a look at what the new blog-ready nbs/ folder will look like.\nMinimal Quarto blog folder structure:\nsample_blog\nâ””â”€â”€â”€nbs/\nâ”‚   â”‚   _quarto.yml\nâ”‚   â”‚   index.ipynb\nâ”‚   â””â”€â”€â”€blog/\nâ”‚       â”‚   index.qmd\nâ”‚       â””â”€â”€â”€posts/\nâ”‚           â””â”€â”€â”€2023-09-24-first-post/     \nâ”‚               â”‚   index.ipynb\nYouâ€™ll notice that nbdev already added the _quarto.yml file. The main change we are making is adding a blog/ folder to the nbs/ directory. This directory has an index.qmd file that tells Quarto about our blog. Hereâ€™s an example index.qmd file that describes our blog and how its posts should be listed:\n---\ntitle: Example Blog\nsubtitle: Publishing with Quarto and nbdev\nlisting:\n  sort: \"date desc\"\n  contents: \"posts\"\n  sort-ui: false\n  filter-ui: false\n  categories: true\n  feed: true\npage-layout: full\n---\nEach post gets its own folder and a matching index.ipynb Notebook with the actual postâ€™s content. Eventually we can add photos, videos, and any other media that enhances the post.\nNext, we will leverage Github Pages to build and host our site for free. The screenshot below shows the settings we need on the Github site for our repo to be published as a blog. Concretely, we need to Deploy from a branch and pick the gh-pages branch.\n\nAnd thatâ€™s all there is to it! We can now publish our first post. Click here for a live link to this Notebook turned into a blog post.\nNow weâ€™ve seen how nbdev lets us quickly create and setup a blog. Next weâ€™ll look at another one of its great capabilities: building a fully fledged python library."
  },
  {
    "objectID": "blog/posts/2023-09-27-Blog-Intro/index.html#creating-python-libraries-with-nbdev",
    "href": "blog/posts/2023-09-27-Blog-Intro/index.html#creating-python-libraries-with-nbdev",
    "title": "nbdev for Blogging and Building Python Libraries",
    "section": "Creating python libraries with nbdev",
    "text": "Creating python libraries with nbdev\nnbdev has a set of helper commands that convert Notebooks into complete python libraries.\nThese helper commands are called directives and usually go at the start of a code cell. They start with the special #| string which is similar to the shebang #! you may have seen in other scripts. These directive tell nbdev how to parse the code cell and what to do with it.\nFor example, the default_exp directive tells nbdev what to name an output python file. We use it below to name this specific python file as lesson_2/simple_pipeline.py:\nAfter weâ€™ve named our soon-to-be python file, the #| export directive will parse and extract any python code cell we attach to it.\n::: {.cell 0=â€˜eâ€™ 1=â€˜xâ€™ 2=â€˜pâ€™ 3=â€˜oâ€™ 4=â€˜râ€™ 5=â€˜tâ€™ execution_count=2}\n# importing the pieces for the pipeline\nfrom transformers import AutoConfig\nfrom transformers import AutoTokenizer\nfrom transformers import AutoModelForSequenceClassification\n\n/Users/cck/mambaforge/envs/llm_base/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n  from .autonotebook import tqdm as notebook_tqdm\n\n:::\n\nA small annoyance: import statements have to be in their own code cell. We canâ€™t pair them with function calls like print(), for example.\n\nNext, we refactor the code from the previous notebook (01_first_run.ipynb) into a simple class.\n::: {.cell 0=â€˜eâ€™ 1=â€˜xâ€™ 2=â€˜pâ€™ 3=â€˜oâ€™ 4=â€˜râ€™ 5=â€˜tâ€™ execution_count=3}\nclass SentimentPipeline:\n    def __init__(self, model_name):\n        \"\"\"\n        Sentiment Analysis pipeline.\n        \"\"\"\n        self.model_name = model_name\n        self.config = AutoConfig.from_pretrained(self.model_name)\n        self.tokenizer = AutoTokenizer.from_pretrained(self.model_name)\n        self.model = AutoModelForSequenceClassification.from_pretrained(self.model_name)\n\n\n    def preprocess(self, text: str):\n        \"\"\"\n        Sends `text` through the LLM's tokenizer.  \n        The tokenizer turns words and characters into special inputs for the LLM.\n        \"\"\"\n        tokenized_inputs = self.tokenizer(text, return_tensors='pt')\n        return tokenized_inputs\n    \n\n    def forward(self, text: str):\n        \"\"\"\n        First we preprocess the `text` into tokens.\n        Then we send the `token_inputs` to the model.\n        \"\"\"\n        token_inputs = self.preprocess(text)\n        outputs = self.model(**token_inputs)\n        return outputs\n    \n\n    def process_outputs(self, outs):\n        \"\"\"\n        Here we mimic the post-processing that HuggingFace automatically does in its `pipeline`.  \n        \"\"\"\n        # grab the raw scores from the model for Positive and Negative labels\n        logits = outs.logits\n\n        # find the strongest label score, aka the model's decision\n        pred_idx = logits.argmax(1).item()\n\n        # use the `config` object to find the actual class label\n        pred_label = self.config.id2label[pred_idx]  \n\n        # calculate the human-readable probability score for this class\n        pred_score = logits.softmax(-1)[:, pred_idx].item()\n\n        # return the predicted label and its score\n        return {\n            'label': pred_label,\n            'score': pred_score, \n        }\n    \n\n    def __call__(self, text: str):\n        \"\"\"\n        Overriding the call method to easily and intuitively call the pipeline.\n        \"\"\"\n        model_outs = self.forward(text)\n        preds = self.process_outputs(model_outs)\n        return preds\n\n    \n    def __repr__(self):\n        \"\"\"\n        Cleaner representation of the pipeline.\n        \"\"\"\n        return f\"SentimentAnalysis_{self.model_name}\"\n:::\nLetâ€™s now make sure that SentimentPipeline actually works, since live tests are one of the main benefits of Notebook coding! Note that since we donâ€™t put an |# export directive in the cell below, it wonâ€™t be part of the exported python file either.\n\n# testing the pipeline\n\n# loading the default model\nmodel_name = 'distilbert-base-uncased-finetuned-sst-2-english'\nclassifier = SentimentPipeline(model_name) \n\n# make sure that the official HuggingFace example works as expected\nresults = classifier(\"We are very happy to show you the ðŸ¤— Transformers library.\"); results\nassert results['label'] == 'POSITIVE'\n\nYou can think of the cell above as a unit test for the SentimentAnalysis pipeline. nbdev runs this notebook when it compiles the library, and if the tests fail then the build fails. This is a great, built-in way of making sure that the library works as expected.\n\nExporting the library\nWe can now export the library using the nbdev_build_lib command. This will create a file inside of the top-level library folder Fractal_LLM_Course. Per the default_exp directive, the file will called lesson_2/simple_pipeline.py.\n\nNote: we can add nested library directories with the typical python dot (.) syntax. For example, if weâ€™d instead used the directive |# default_exp simple_pipeline, then the file would live at the top-level library folder: Fractal_LLM_Course/simple_pipeline.py. Adding the lesson_2. created the lesson_2/ folder for us.\n\nThe following set of commands will:\n- Export the Notebooks into a library.\n- Install the library as an editable install. - Import the newly installed library in a python shell.\nMake sure to run them from the top-level directory of the repo.\n# export Notebooks into a library\nnbdev_export_lib  \n\n# install the library as an editable install\npip install -e . \nNow open up a python shell to import and use the library.\n# import the newly installed library \nfrom Fractal_LLM_Course.lesson_2.simple_pipeline import SentimentPipeline\n\n# use our custom SentimentAnalysis pipeline!\nmodel_name = 'distilbert-base-uncased-finetuned-sst-2-english'\nclassifier = SentimentPipeline(model_name) \nCongrats! Weâ€™ve now built and installed a full, working python library. This is just the start, nbdev has many other advanced tools you can read about here."
  },
  {
    "objectID": "00_core.html",
    "href": "00_core.html",
    "title": "core",
    "section": "",
    "text": "Fill in a module description here\n\n::: {.cell 0=â€˜hâ€™ 1=â€˜iâ€™ 2=â€˜dâ€™ 3=â€˜eâ€™}\nfrom nbdev.showdoc import *\n:::\n::: {.cell 0=â€˜eâ€™ 1=â€˜xâ€™ 2=â€˜pâ€™ 3=â€˜oâ€™ 4=â€˜râ€™ 5=â€˜tâ€™}\ndef foo(): pass\n\ndef my_first_function():\n    \"\"\"Simple greeter.\"\"\"\n    print(\"Hello, world!\")\n:::\n::: {.cell 0=â€˜hâ€™ 1=â€˜iâ€™ 2=â€˜dâ€™ 3=â€˜eâ€™}\nimport nbdev; nbdev.nbdev_export()\n:::"
  },
  {
    "objectID": "blog/index.html",
    "href": "blog/index.html",
    "title": "Example Fractal-U Blog",
    "section": "",
    "text": "nbdev for Blogging and Building Python Libraries\n\n\n\n\n\n\n\nfractal\n\n\npython\n\n\nnbdev\n\n\n\n\n\n\n\n\n\n\n\nSep 27, 2022\n\n\nenzokro\n\n\n\n\n\n\nNo matching items"
  }
]