<?xml version="1.0" encoding="UTF-8"?>
<rss  xmlns:atom="http://www.w3.org/2005/Atom" 
      xmlns:media="http://search.yahoo.com/mrss/" 
      xmlns:content="http://purl.org/rss/1.0/modules/content/" 
      xmlns:dc="http://purl.org/dc/elements/1.1/" 
      version="2.0">
<channel>
<title>sample_blog_2</title>
<link>https://enzokro.github.io/sample_blog_2/blog/index.html</link>
<atom:link href="https://enzokro.github.io/sample_blog_2/blog/index.xml" rel="self" type="application/rss+xml"/>
<description>Creating a sample blog with nbdev</description>
<generator>quarto-1.3.450</generator>
<lastBuildDate>Tue, 27 Sep 2022 04:00:00 GMT</lastBuildDate>
<item>
  <title>nbdev for Blogging and Building Python Libraries</title>
  <dc:creator>enzokro </dc:creator>
  <link>https://enzokro.github.io/sample_blog_2/blog/posts/2023-09-27-Third-Post/index.html</link>
  <description><![CDATA[ 



<section id="goals" class="level2">
<h2 class="anchored" data-anchor-id="goals">Goals:</h2>
<ul>
<li>Create a blog and publish our first post.<br>
</li>
<li>Build a custom, dynamic python library for the Sentiment Analysis pipeline in <code>01_first_runs.ipynb</code>.</li>
</ul>
</section>
<section id="intro" class="level2">
<h2 class="anchored" data-anchor-id="intro">Intro:</h2>
<p>This Notebook takes a closer look at the <code>nbdev</code> library. <code>nbdev</code> is a powerful tool built around two key ideas:<br>
- <a href="">Literate Programming</a>. - <a href="">Exploratory Programming</a>.</p>
<p>The next sections give an overview of these topics, and why their combination is useful for us.</p>
<section id="literate-programming" class="level3">
<h3 class="anchored" data-anchor-id="literate-programming">Literate Programming</h3>
<p>In Literate Programming, descriptions (documentation) are woven directly into a project‚Äôs source code. This is opposite from most codebases where documentation lives in a separate set of files. It also goes beyond tools like <a href="https://www.sphinx-doc.org/en/master/">sphinx</a> that instead parse comments and docstrings into documentation.</p>
<p>Code, tests, and documentation are all first-class citizens in Literate Programming. In <code>nbdev</code> a Notebook is the single, unified source for all three things. Instead of having to independently manage code, docs, and tests, everything happens in the Notebook. If the Notebook runs then you know your code will run. The tight integration between what you‚Äôre doing (code), describing what you‚Äôre doing (documentation), and making sure it‚Äôs correct (tests) is a great approach for both research and thinking in general.</p>
</section>
<section id="exploratory-programming" class="level3">
<h3 class="anchored" data-anchor-id="exploratory-programming">Exploratory Programming</h3>
<p>Exploratory Programming is an open-ended approach for new problems and unknown domains. It‚Äôs very helpful at the start of a project before its scope or requirements are fully flushed out.</p>
<p>The interactive and dynamic nature of Notebooks is ideal for Exploratory Programming. It makes the barrier to try new things extremely low. And it‚Äôs fun! Jupyter also has many extra tools to inspect code and debug its outputs.</p>
</section>
<section id="combining-literate-and-exploratory-programming" class="level3">
<h3 class="anchored" data-anchor-id="combining-literate-and-exploratory-programming">Combining Literate and Exploratory Programming</h3>
<p><code>nbdev</code>‚Äôs main workflow combines these two ideas. It‚Äôs a great combo for trying things out, figuring out what they do, and how they work. We can poke around and explore codebases in a much more interactive way than usual. Iterations are fast and cheap so it‚Äôs easy to follow any hit of curiosity. And if anything breaks, we can always restart the Notebook and try again!</p>
<p>We can also mix and match these ideas as needed. For example at the start of a project, while finding our footing, we might lean Exploratory. Then as the idea matures, we could lean Literate to refine and crystallize our approach.</p>
<p>Now for our first goal: creating and publishing a blog post.</p>
</section>
</section>
<section id="turning-notebooks-into-blog-posts" class="level2">
<h2 class="anchored" data-anchor-id="turning-notebooks-into-blog-posts">Turning Notebooks into Blog Posts</h2>
<p>First, a high-level summary of the steps to create the blog.</p>
<section id="high-level-steps" class="level3">
<h3 class="anchored" data-anchor-id="high-level-steps">High-Level Steps:</h3>
<ol type="1">
<li>Create a new nbdev project.<br>
</li>
<li>Set up the minimum requirements for an nbdev blog.<br>
</li>
<li>Publish the blog to Github pages.</li>
</ol>
<blockquote class="blockquote">
<p>NOTE: This section is based on these two references: - <a href="https://nbdev.fast.ai/tutorials/tutorial.html#installation">Official nbdev tutorial.</a> - <a href="https://nbdev.fast.ai/tutorials/blogging.html">Blogging with nbdev.</a></p>
</blockquote>
<p><code>nbdev</code> leverages an amazing tool called <a href="https://quarto.org/">Quarto</a> for blogging. Quarto is a publishing framework tailored to scientific and technical articles and posts. In a way it‚Äôs a blogging platform for Literate Programming, where a series of code cells tell a story and take the reader on a journey.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://enzokro.github.io/sample_blog_2/blog/posts/2023-09-27-Third-Post/quarto.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Alt text</figcaption>
</figure>
</div>
</section>
<section id="creating-a-new-nbdev-project" class="level3">
<h3 class="anchored" data-anchor-id="creating-a-new-nbdev-project">Creating a new <code>nbdev</code> project</h3>
<p><code>nbdev</code> works on top of a Git repo, so the step is creating an empty git repository. Here is a handy <a href="https://github.com/new">Github link</a> that takes you straight to the page for creating new repos.</p>
<blockquote class="blockquote">
<p>Note: We need a completely empty repo, so don‚Äôt include a <code>.gitignore</code> or <code>README.md</code>.</p>
</blockquote>
<p>In this example the empty repo is called <code>sample_blog</code>, but feel free to call it anything you‚Äôd like. We‚Äôre not married to this name either, we can always create new repos with different, better names.</p>
<p>Next, clone this repo to your computer. Make sure to change the github link below to point to your repo instead.</p>
<div class="sourceCode" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb1-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># clone the repo to your computer</span></span>
<span id="cb1-2"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">git</span> clone https://github.com/enzokro/sample_blog.git <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># &lt;-- ! link with your repo here</span></span></code></pre></div>
<p>Now we can move into this empty repo and let <code>nbdev</code> work its initialization magic. Run the <code>nbdev_new</code> command to get started. It will prompt you for some general info like as a short description about your project.</p>
<div class="sourceCode" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb2-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># move into the new repo and initialize the nbdev project</span></span>
<span id="cb2-2"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">cd</span> sample_blog/</span>
<span id="cb2-3"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">nbdev_new</span></span></code></pre></div>
<p>All of the options and configs for your project are found in the <code>settings.ini</code> file. <code>nbdev</code> looks in this file for any info it needs for its commands.</p>
<p>When <code>nbdev_new</code> finishes running, you will have a new <code>nbdev</code> project! Try running a <code>git status</code> command to see everything that was added.</p>
<p>We can now commit and push these changes to Github.</p>
<div class="sourceCode" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb3-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># add, commit, and push the files created by nbdev</span></span>
<span id="cb3-2"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">git</span> add .</span>
<span id="cb3-3"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">git</span> commit <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">-m</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Initial nbdev project creation'</span></span>
<span id="cb3-4"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">git</span> push</span></code></pre></div>
<p>As we mentioned earlier, <code>nbdev</code> leverages Quarto for publishing Notebooks. The next steps are turning this nbdev project into a proper Quarto blog.</p>
</section>
<section id="adding-quarto-to-the-mix" class="level3">
<h3 class="anchored" data-anchor-id="adding-quarto-to-the-mix">Adding Quarto to the Mix</h3>
<p>Start by activating the virtual environment:</p>
<div class="sourceCode" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb4-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># acivate the environment</span></span>
<span id="cb4-2"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">mamba</span> activate llm_base</span></code></pre></div>
<p><code>nbdev</code> includes a way to install Quarto using the <code>nbdev_install_quarto</code> command. Go ahead and run it, but note that it will ask you for administrator privileges.</p>
<div class="sourceCode" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb5-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># install quarto</span></span>
<span id="cb5-2"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">nbdev_install_quarto</span></span></code></pre></div>
<p>You may need to refresh the terminal session before it can find the <code>quarto</code> commands. To be safe, open up a new terminal and re-activate the environment. Then the command below will check if Quarto was installed successfully.</p>
<div class="sourceCode" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb6-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># shows us where quarto is installed</span></span>
<span id="cb6-2"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">which</span> quarto </span></code></pre></div>
<p>Note that the <code>nbs/</code> folder usually holds the Notebooks that become a project‚Äôs documentation, tests, and source code. To make sure Quarto can publish an <code>nbdev</code> blog we have to add some files and change this directory structure a bit.</p>
<p>First let‚Äôs take a look at what the new blog-ready <code>nbs/</code> folder will look like.</p>
<p><strong>Minimal Quarto blog folder structure</strong>:</p>
<pre><code>sample_blog
‚îî‚îÄ‚îÄ‚îÄnbs/
‚îÇ   ‚îÇ   _quarto.yml
‚îÇ   ‚îÇ   index.ipynb
‚îÇ   ‚îî‚îÄ‚îÄ‚îÄblog/
‚îÇ       ‚îÇ   index.qmd
‚îÇ       ‚îî‚îÄ‚îÄ‚îÄposts/
‚îÇ           ‚îî‚îÄ‚îÄ‚îÄ2023-09-24-first-post/     
‚îÇ               ‚îÇ   index.ipynb</code></pre>
<p>You‚Äôll notice that <code>nbdev</code> already added the <code>_quarto.yml</code> file. The main change we are making is adding a <code>blog/</code> folder to the <code>nbs/</code> directory. This directory has an <code>index.qmd</code> file that tells Quarto about our blog. Here‚Äôs an example <code>index.qmd</code> file that describes our blog and how its posts should be listed:</p>
<div class="sourceCode" id="cb8" style="background: #f1f3f5;"><pre class="sourceCode yaml code-with-copy"><code class="sourceCode yaml"><span id="cb8-1"><span class="pp" style="color: #AD0000;
background-color: null;
font-style: inherit;">---</span></span>
<span id="cb8-2"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">title</span><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">:</span><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;"> Example Blog</span></span>
<span id="cb8-3"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">subtitle</span><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">:</span><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;"> Publishing with Quarto and nbdev</span></span>
<span id="cb8-4"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">listing</span><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">:</span></span>
<span id="cb8-5"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">  </span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">sort</span><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">:</span><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;"> </span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"date desc"</span></span>
<span id="cb8-6"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">  </span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">contents</span><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">:</span><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;"> </span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"posts"</span></span>
<span id="cb8-7"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">  </span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">sort-ui</span><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">:</span><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;"> </span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">false</span></span>
<span id="cb8-8"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">  </span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">filter-ui</span><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">:</span><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;"> </span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">false</span></span>
<span id="cb8-9"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">  </span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">categories</span><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">:</span><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;"> </span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">true</span></span>
<span id="cb8-10"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">  </span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">feed</span><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">:</span><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;"> </span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">true</span></span>
<span id="cb8-11"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">page-layout</span><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">:</span><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;"> full</span></span>
<span id="cb8-12"><span class="pp" style="color: #AD0000;
background-color: null;
font-style: inherit;">---</span></span></code></pre></div>
<p>Each post gets its own folder and a matching <code>index.ipynb</code> Notebook with the actual post‚Äôs content. Eventually we can add photos, videos, and any other media that enhances the post.</p>
<p>Next, we will leverage <a href="https://pages.github.com/">Github Pages</a> to build and host our site for free. The screenshot below shows the settings we need on the Github site for our repo to be published as a blog. Concretely, we need to <code>Deploy from a branch</code> and pick the <code>gh-pages</code> branch.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://enzokro.github.io/sample_blog_2/blog/posts/2023-09-27-Third-Post/github_pages.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">image.png</figcaption>
</figure>
</div>
<p>And that‚Äôs all there is to it! We can now publish our first post. <a href="">Click here</a> for a live link to this Notebook turned into a blog post.</p>
<p>Now we‚Äôve seen how <code>nbdev</code> lets us quickly create and setup a blog. Next we‚Äôll look at another one of its great capabilities: building a fully fledged python library.</p>
</section>
</section>
<section id="creating-python-libraries-with-nbdev" class="level2">
<h2 class="anchored" data-anchor-id="creating-python-libraries-with-nbdev">Creating python libraries with <code>nbdev</code></h2>
<p><code>nbdev</code> has a set of helper commands that convert Notebooks into complete python libraries.</p>
<p>These helper commands are called <code>directives</code> and usually go at the start of a code cell. They start with the special <code>#|</code> string which is similar to the shebang <code>#!</code> you may have seen in other scripts. These directive tell <code>nbdev</code> how to parse the code cell and what to do with it.</p>
<p>For example, the <code>default_exp</code> directive tells <code>nbdev</code> what to name an output python file. We use it below to name this specific python file as <code>lesson_2/simple_pipeline.py</code>:</p>
<p>After we‚Äôve named our soon-to-be python file, the <code>#| export</code> directive will parse and extract any python code cell we attach to it.</p>
<p>::: {.cell 0=‚Äòe‚Äô 1=‚Äòx‚Äô 2=‚Äòp‚Äô 3=‚Äòo‚Äô 4=‚Äòr‚Äô 5=‚Äòt‚Äô execution_count=2}</p>
<div class="sourceCode cell-code" id="cb9" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># importing the pieces for the pipeline</span></span>
<span id="cb9-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> transformers <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> AutoConfig</span>
<span id="cb9-3"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> transformers <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> AutoTokenizer</span>
<span id="cb9-4"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> transformers <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> AutoModelForSequenceClassification</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>/Users/cck/mambaforge/envs/llm_base/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html
  from .autonotebook import tqdm as notebook_tqdm</code></pre>
</div>
<p>:::</p>
<blockquote class="blockquote">
<p>A small annoyance: <code>import</code> statements have to be in their own code cell. We can‚Äôt pair them with function calls like <code>print()</code>, for example.</p>
</blockquote>
<p>Next, we refactor the code from the previous notebook (<code>01_first_run.ipynb</code>) into a simple class.</p>
<p>::: {.cell 0=‚Äòe‚Äô 1=‚Äòx‚Äô 2=‚Äòp‚Äô 3=‚Äòo‚Äô 4=‚Äòr‚Äô 5=‚Äòt‚Äô execution_count=3}</p>
<div class="sourceCode cell-code" id="cb11" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">class</span> SentimentPipeline:</span>
<span id="cb11-2">    <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">__init__</span>(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, model_name):</span>
<span id="cb11-3">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""</span></span>
<span id="cb11-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        Sentiment Analysis pipeline.</span></span>
<span id="cb11-5"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        """</span></span>
<span id="cb11-6">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.model_name <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> model_name</span>
<span id="cb11-7">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.config <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> AutoConfig.from_pretrained(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.model_name)</span>
<span id="cb11-8">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.tokenizer <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> AutoTokenizer.from_pretrained(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.model_name)</span>
<span id="cb11-9">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.model <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> AutoModelForSequenceClassification.from_pretrained(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.model_name)</span>
<span id="cb11-10"></span>
<span id="cb11-11"></span>
<span id="cb11-12">    <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> preprocess(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, text: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">str</span>):</span>
<span id="cb11-13">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""</span></span>
<span id="cb11-14"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        Sends `text` through the LLM's tokenizer.  </span></span>
<span id="cb11-15"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        The tokenizer turns words and characters into special inputs for the LLM.</span></span>
<span id="cb11-16"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        """</span></span>
<span id="cb11-17">        tokenized_inputs <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.tokenizer(text, return_tensors<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'pt'</span>)</span>
<span id="cb11-18">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> tokenized_inputs</span>
<span id="cb11-19">    </span>
<span id="cb11-20"></span>
<span id="cb11-21">    <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> forward(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, text: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">str</span>):</span>
<span id="cb11-22">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""</span></span>
<span id="cb11-23"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        First we preprocess the `text` into tokens.</span></span>
<span id="cb11-24"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        Then we send the `token_inputs` to the model.</span></span>
<span id="cb11-25"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        """</span></span>
<span id="cb11-26">        token_inputs <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.preprocess(text)</span>
<span id="cb11-27">        outputs <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.model(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">**</span>token_inputs)</span>
<span id="cb11-28">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> outputs</span>
<span id="cb11-29">    </span>
<span id="cb11-30"></span>
<span id="cb11-31">    <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> process_outputs(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, outs):</span>
<span id="cb11-32">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""</span></span>
<span id="cb11-33"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        Here we mimic the post-processing that HuggingFace automatically does in its `pipeline`.  </span></span>
<span id="cb11-34"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        """</span></span>
<span id="cb11-35">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># grab the raw scores from the model for Positive and Negative labels</span></span>
<span id="cb11-36">        logits <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> outs.logits</span>
<span id="cb11-37"></span>
<span id="cb11-38">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># find the strongest label score, aka the model's decision</span></span>
<span id="cb11-39">        pred_idx <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> logits.argmax(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>).item()</span>
<span id="cb11-40"></span>
<span id="cb11-41">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># use the `config` object to find the actual class label</span></span>
<span id="cb11-42">        pred_label <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.config.id2label[pred_idx]  </span>
<span id="cb11-43"></span>
<span id="cb11-44">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># calculate the human-readable probability score for this class</span></span>
<span id="cb11-45">        pred_score <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> logits.softmax(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)[:, pred_idx].item()</span>
<span id="cb11-46"></span>
<span id="cb11-47">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># return the predicted label and its score</span></span>
<span id="cb11-48">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> {</span>
<span id="cb11-49">            <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'label'</span>: pred_label,</span>
<span id="cb11-50">            <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'score'</span>: pred_score, </span>
<span id="cb11-51">        }</span>
<span id="cb11-52">    </span>
<span id="cb11-53"></span>
<span id="cb11-54">    <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">__call__</span>(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, text: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">str</span>):</span>
<span id="cb11-55">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""</span></span>
<span id="cb11-56"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        Overriding the call method to easily and intuitively call the pipeline.</span></span>
<span id="cb11-57"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        """</span></span>
<span id="cb11-58">        model_outs <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.forward(text)</span>
<span id="cb11-59">        preds <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.process_outputs(model_outs)</span>
<span id="cb11-60">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> preds</span>
<span id="cb11-61"></span>
<span id="cb11-62">    </span>
<span id="cb11-63">    <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">__repr__</span>(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>):</span>
<span id="cb11-64">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""</span></span>
<span id="cb11-65"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        Cleaner representation of the pipeline.</span></span>
<span id="cb11-66"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        """</span></span>
<span id="cb11-67">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> <span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"SentimentAnalysis_</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span>model_name<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span></span></code></pre></div>
<p>:::</p>
<p>Let‚Äôs now make sure that <code>SentimentPipeline</code> actually works, since live tests are one of the main benefits of Notebook coding! Note that since we don‚Äôt put an <code>|# export</code> directive in the cell below, it won‚Äôt be part of the exported python file either.</p>
<div class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb12" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># testing the pipeline</span></span>
<span id="cb12-2"></span>
<span id="cb12-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># loading the default model</span></span>
<span id="cb12-4">model_name <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'distilbert-base-uncased-finetuned-sst-2-english'</span></span>
<span id="cb12-5">classifier <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> SentimentPipeline(model_name) </span>
<span id="cb12-6"></span>
<span id="cb12-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># make sure that the official HuggingFace example works as expected</span></span>
<span id="cb12-8">results <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> classifier(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"We are very happy to show you the ü§ó Transformers library."</span>)<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">;</span> results</span>
<span id="cb12-9"><span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">assert</span> results[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'label'</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'POSITIVE'</span></span></code></pre></div>
</div>
<p>You can think of the cell above as a unit test for the <code>SentimentAnalysis</code> pipeline. <code>nbdev</code> runs this notebook when it compiles the library, and if the tests fail then the build fails. This is a great, built-in way of making sure that the library works as expected.</p>
<section id="exporting-the-library" class="level3">
<h3 class="anchored" data-anchor-id="exporting-the-library">Exporting the library</h3>
<p>We can now export the library using the <code>nbdev_build_lib</code> command. This will create a file inside of the top-level library folder <code>Fractal_LLM_Course</code>. Per the <code>default_exp</code> directive, the file will called <code>lesson_2/simple_pipeline.py</code>.</p>
<blockquote class="blockquote">
<p>Note: we can add nested library directories with the typical python dot (<code>.</code>) syntax. For example, if we‚Äôd instead used the directive <code>|# default_exp simple_pipeline</code>, then the file would live at the top-level library folder: <code>Fractal_LLM_Course/simple_pipeline.py</code>. Adding the <code>lesson_2.</code> created the <code>lesson_2/</code> folder for us.</p>
</blockquote>
<p>The following set of commands will:<br>
- Export the Notebooks into a library.<br>
- Install the library as an editable install. - Import the newly installed library in a python shell.</p>
<p>Make sure to run them from the top-level directory of the repo.</p>
<div class="sourceCode" id="cb13" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb13-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># export Notebooks into a library</span></span>
<span id="cb13-2"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">nbdev_export_lib</span>  </span>
<span id="cb13-3"></span>
<span id="cb13-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># install the library as an editable install</span></span>
<span id="cb13-5"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">pip</span> install <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">-e</span> . </span></code></pre></div>
<p>Now open up a python shell to import and use the library.</p>
<div class="sourceCode" id="cb14" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># import the newly installed library </span></span>
<span id="cb14-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> Fractal_LLM_Course.lesson_2.simple_pipeline <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> SentimentPipeline</span>
<span id="cb14-3"></span>
<span id="cb14-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># use our custom SentimentAnalysis pipeline!</span></span>
<span id="cb14-5">model_name <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'distilbert-base-uncased-finetuned-sst-2-english'</span></span>
<span id="cb14-6">classifier <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> SentimentPipeline(model_name) </span></code></pre></div>
<p>Congrats! We‚Äôve now built and installed a full, working python library. This is just the start, <code>nbdev</code> has many other advanced tools you can <a href="https://nbdev.fast.ai/tutorials/tutorial.html#advanced-functionality">read about here</a>.</p>
</section>
</section>
<section id="conclusion" class="level1">
<h1>Conclusion</h1>
<p>This Notebook covered two key features of <code>nbdev</code>:<br>
- Creating a blog. - Building a python library.</p>
<p>Both of these features are great for research and development. We can quickly try new ideas and easily share them with others.</p>


</section>

 ]]></description>
  <category>fractal</category>
  <category>python</category>
  <category>nbdev</category>
  <guid>https://enzokro.github.io/sample_blog_2/blog/posts/2023-09-27-Third-Post/index.html</guid>
  <pubDate>Tue, 27 Sep 2022 04:00:00 GMT</pubDate>
  <media:content url="https://enzokro.github.io/sample_blog_2/blog/posts/2023-09-27-Third-Post/nbdev_pic.png" medium="image" type="image/png" height="66" width="144"/>
</item>
<item>
  <title>Environment setups</title>
  <link>https://enzokro.github.io/sample_blog_2/blog/posts/2023-09-24-First-Post/index.html</link>
  <description><![CDATA[ 



<blockquote class="blockquote">
<p>Running a Large Language Model using the HuggingFace <code>Transformers</code> API.</p>
</blockquote>
<section id="introduction" class="level1">
<h1>Introduction</h1>
<p>The goal of this course is to build an AI Agent by fine-tuning a Large Language Model (LLM) on documents chosen by each student. What exactly do we mean by Agent, and why would we focus on a simple one?</p>
<p>To give some context, there is a lot of talk and hype around Agents at the moment. Folks are looking towards a future where we all have personalized AI assistants, aka Agents, at our fingertips. These Agents will make our lives better both in the day to day and in the long term. They are the AI assistants of Science Fiction made material. Agents like TARS from Interstellar, Jarvis from Iron Man, HAL 9000 from Space Odyssey, Samantha from Her, etc.</p>
<p>For as fast as the progress in AI and LLMs has been, Agents as powerful as those are still a ways off. It‚Äôs hard if not impossible to predict the exact timelines. Suffice it to say that these Agents won‚Äôt be here anytime ‚Äúsoon‚Äù. But, barring some force majeure, they <em>will</em> exist at some point.</p>
<p>The gap, then, is that folks are talking about (and promising) these advanced Agent capabilities, while on the ground we are still dealing with LLM hallucinations and prohibitive compute requirements.</p>
<p>Where does that leave us? Well, as <a href="https://twitter.com/gdb/status/1694107518488981868">a recent announcement from OpenAI</a> shows, fine-tuning GPT-3.5 on small, clean datasets can even surpass GPT-4 on certain tasks. <em>That‚Äôs</em> what we are aiming for. In other words, we already have the ability to develop outrageously powerful tools by fine-tuning LLMs on small, clean datasets.</p>
<p>So we won‚Äôt build a simple chatbot, nor will we be build Iron Man‚Äôs Jarvis. We will land somewhere in the middle. If it helps, try thinking about this simple Agent as an Intelligent Rubber Duck. In case you‚Äôre not familiar with the concept: a Rubber Duck is anything (actual yellow rubber duckie optional) that you keep around your desk and talk to about your work. It is a physical tool for thought, since it‚Äôs so often helpful to say out loud the swarm of thoughts in our head.</p>
<p>Our simple Agent will be a Rubber Duck that speaks back at you. When you ask it a question about your work, it will respond given what it knows about the project as a whole. Or, if you are simply verbalizing a thought to untangle it, the Agent will give you some feedback or suggest other approaches. If we can be so bold: our Agent will be a Jarvis-lite, laser-focused on a narrow scope. Then, as both the tools and tech progresses, we‚Äôll have everything needed to unlock even more capabilities from our Intelligent Rubber Duck.</p>
<blockquote class="blockquote">
<p>Summary: In this course we will fine-tune an LLM on a small, clean dataset of our choosing to build an Intelligent Rubber Duck that can help us work or create better.</p>
</blockquote>
<section id="things-we-need-for-the-class" class="level2">
<h2 class="anchored" data-anchor-id="things-we-need-for-the-class">Things we need for the class</h2>
<p>In order to fully use a current, open source LLM, the first thing we need to do is set up a proper <code>programming environment</code>. The environment is a computing ecosystem with all the software libraries and packages needed to run an LLM.</p>
<p>Note that setting up this environment is often one of the most time-consuming and challenging tasks when it comes to Machine Learning. There is no silver bullet or universal solution, as you will see by the dozens of tools that folks have come up with to tackle this problem (insert xkcd comic about competing standards).</p>
<p>The main point here is that setting up the environment is often annoying. It can even be straight up painful. It‚Äôs ok to feel lost or struggle with it. Please take some comfort in the fact that once we have the environment, many of the downstream tasks will feel easy by comparison!</p>
<p>So what makes building this environment so challenging? And why do we need it in the first place?</p>
<section id="silent-failures-in-ai-models" class="level4">
<h4 class="anchored" data-anchor-id="silent-failures-in-ai-models">Silent Failures in AI Models</h4>
<p>LLMs, and Machine Learning models more generally, often fail in different ways than other, standard software fails. For instance, classic bugs in regular software include: type mismatches, syntax errors, compilation errors, etc. In other words failures that clearly stem from a <em>wrong</em> operation (aka a bug) that snuck into the code. We wanted the computer to do <code>X</code>, but we told it by accident to do <code>Y</code> instead.</p>
<p>In contrast, ML models often have ‚Äúsilent‚Äù failures. There is no syntax or compilation error - the program still runs and completes fine. But, there is <em>something</em> wrong in the code: adding where we should have subtracted, grabbing the wrong element from a list, or using the wrong mathematical function. There is no type checker or compiler that would (or even could, for now) catch these errors.</p>
<p>The fix for the silent failures above is clear:<br>
- Carefully inspecting the code.<br>
- Monitoring and validating its outputs.<br>
- Clarity in both the algorithms and models we are using.</p>
<p>There is another, unfortunate kind of silent failure: <code>version</code> mismatches. Version failures happen when we use a different version of a programming library than the version originally used by the model. As the software libraries we rely on are frequently updated, both subtle and major changes in their internals can affect the output of a model. These failures are unfortunately immune to our careful logical checks.</p>
<p>Avoiding these silent failures is the main reason for being consistent and disciplined with our model‚Äôs programming environment. A good environment setup keeps us focused on the important, conceptual part of our model instead of getting bogged down in managing software versions.</p>
</section>
<section id="looking-forward-with-our-environment" class="level4">
<h4 class="anchored" data-anchor-id="looking-forward-with-our-environment">Looking forward with our environment</h4>
<p>There is a nice benefit to spending this much time and effort up front on our environment.</p>
<p>We will not only have a specialized environment to run and fine-tune a single LLM. We‚Äôll have a springboard and setup to keep up with the state of the art in the field. A setup to bring in groundbreaking improvements as they are released. And to weave in the latest and greatest models. The LLM world is our oyster, and the base environment the grain of sand soon-to-be pearls.</p>
</section>
</section>
<section id="organizing-what-we-need" class="level2">
<h2 class="anchored" data-anchor-id="organizing-what-we-need">Organizing what we need</h2>
<p>The <code>mamba</code> package manager will handle the python version. Why Mamba? To start it is way fast and better than Anaconda, and it makes it easier to install OS and system-level packages we need outside of python.</p>
<p>We will use <code>pip</code> to install the actual python packages. Note that we could use mamba for this as well, but a few of the libraries need custom pip options to install.</p>
<blockquote class="blockquote">
<p>Note: Run <code>pip install -e .</code> to install a dynamic version of this package that tracks live code changes.</p>
</blockquote>
</section>
</section>
<section id="installing-mamba-on-our-computers" class="level1">
<h1>Installing <code>mamba</code> on our computers</h1>
<p>Follow the steps in the <a href="https://github.com/conda-forge/miniforge#install">official install instructions</a>.</p>
<section id="mac-installation" class="level2">
<h2 class="anchored" data-anchor-id="mac-installation">Mac Installation</h2>
<p>First find the name of your architecture. We then use it to pick the right install script for each Mac.</p>
<div class="sourceCode" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb1-1"></span>
<span id="cb1-2"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># check your mac's architecture</span></span>
<span id="cb1-3"><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">arch</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">$(</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">uname</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">)</span> </span>
<span id="cb1-4"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">echo</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">$arch</span></span>
<span id="cb1-5"></span>
<span id="cb1-6"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># download the appropriate installation script</span></span>
<span id="cb1-7"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">curl</span> <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">-L</span> <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">-O</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"https://github.com/conda-forge/miniforge/releases/latest/download/Mambaforge-</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">$(</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">uname</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">)</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">-</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">$(</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">uname</span> <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">-m</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">)</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">.sh"</span></span>
<span id="cb1-8"></span>
<span id="cb1-9"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># run the Mambaforge installer</span></span>
<span id="cb1-10"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">bash</span> Mambaforge-<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">$(</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">uname</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">)</span>-<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">$(</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">uname</span> <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">-m</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">)</span>.sh</span></code></pre></div>
<p>If you prefer to download the file directly, grab it from here:</p>
<p>https://github.com/conda-forge/miniforge/releases/</p>
</section>
<section id="creating-the-environment" class="level2">
<h2 class="anchored" data-anchor-id="creating-the-environment">Creating the environment</h2>
<p>After installing Mamba, head to the Lesson 0 here: <code>Fractal_LLM_Course/lesson_0/envs</code>. The <code>README.md</code> in that folder has the full instructions to build the mamba environment.</p>


</section>
</section>

 ]]></description>
  <guid>https://enzokro.github.io/sample_blog_2/blog/posts/2023-09-24-First-Post/index.html</guid>
  <pubDate>Wed, 27 Sep 2023 23:19:41 GMT</pubDate>
</item>
<item>
  <title>Run a Large Language Model using the HuggingFace Transformers API.</title>
  <link>https://enzokro.github.io/sample_blog_2/blog/posts/2023-09-24-Second-Post/index.html</link>
  <description><![CDATA[ 



<p>The cells below are good defaults for development.</p>
<p>The <code>autoreload</code> lines help load libraries on the fly, while they are changing. This works well with the editable install we created via <code>pip install -e .</code><br>
This means we can edit the source code directly and have the change reflected live in the notebook.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%</span>load_ext autoreload</span>
<span id="cb1-2"><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%</span>autoreload <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span></span>
<span id="cb1-3"><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%</span>matplotlib inline</span></code></pre></div>
</div>
<section id="introduction" class="level1">
<h1>Introduction</h1>
<p>Imagine we have a list of product review from our users. Now we want to find out whether those reviews were good or bad. It will take a lot of effort to manually go through and check each one. But, using an LLM, we can automatically get a label for a given product review.</p>
<p>How would this be useful? We could use it to find the more negative reviews to see where our product needs improving. Or, we can look at the more positive ones to see what we‚Äôre doing right.</p>
<p>The broader task in NLP of figuring out a statement‚Äôs tone is called <code>Sentiment Analysis</code>.</p>
<section id="first-a-pipeline" class="level2">
<h2 class="anchored" data-anchor-id="first-a-pipeline">First, a Pipeline</h2>
<p>A HuggingFace model is based on 3 key pieces: 1. Config file.<br>
2. Preprocessor file.<br>
3. Model file.</p>
<p>The HuggingFace API gives us a way of automatically using these pieces directly: the <code>pipeline</code>.</p>
<p>Let‚Äôs get right it and create a Sentiment Analysis <code>pipeline</code>.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># load in the pipeline object from huggingface</span></span>
<span id="cb2-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> transformers <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> pipeline</span>
<span id="cb2-3"></span>
<span id="cb2-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># create the sentiment analysis pipeline</span></span>
<span id="cb2-5">classifier <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pipeline(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"sentiment-analysis"</span>)</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>/Users/cck/mambaforge/envs/llm_base/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html
  from .autonotebook import tqdm as notebook_tqdm
No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).
Using a pipeline without specifying a model name and revision in production is not recommended.
Downloading (‚Ä¶)lve/main/config.json: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 629/629 [00:00&lt;00:00, 1.06MB/s]
Downloading model.safetensors: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 268M/268M [00:34&lt;00:00, 7.76MB/s] 
Downloading (‚Ä¶)okenizer_config.json: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 48.0/48.0 [00:00&lt;00:00, 432kB/s]
Downloading (‚Ä¶)solve/main/vocab.txt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 232k/232k [00:00&lt;00:00, 9.00MB/s]</code></pre>
</div>
</div>
<p>We can see in the output message above that HuggingFace automatically picked a decent, default model for us since we didn‚Äôt specify one. Specifically, it chose a <a href="distilbert-base-uncased-finetuned-sst-2-english">distilbert model</a>.</p>
<p>We will learn more about what exactly <code>distilbert</code> is and how it works later on. For now, think of it as a useful NLP genie who can tell us how it feels about a given sentence.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># example from the HuggingFace tutorial</span></span>
<span id="cb4-2">classifier(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"We are very happy to show you the ü§ó Transformers library."</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<pre><code>[{'label': 'POSITIVE', 'score': 0.9997795224189758}]</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># passing in several sentences at once, inside a python list</span></span>
<span id="cb6-2">results <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> classifier([</span>
<span id="cb6-3">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"We are very happy to show you the ü§ó Transformers library."</span>,</span>
<span id="cb6-4">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"We hope you don't hate it."</span>,</span>
<span id="cb6-5">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"I love Fractal! I'm so glad it's not a cult!"</span>, </span>
<span id="cb6-6">])</span>
<span id="cb6-7"></span>
<span id="cb6-8"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># print the output of each results</span></span>
<span id="cb6-9"><span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> result <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> results:</span>
<span id="cb6-10">    <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"label: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>result[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'label'</span>]<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">, with score: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">round</span>(result[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'score'</span>], <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>)<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>label: POSITIVE, with score: 0.9998
label: NEGATIVE, with score: 0.5309
label: POSITIVE, with score: 0.999</code></pre>
</div>
</div>
</section>
</section>
<section id="inspecting-the-classifier-notebook-style." class="level1">
<h1>Inspecting the <code>classifier</code>, notebook style.</h1>
<p>What is the <code>classifier</code>, exactly?</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb8" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1">classifier</span></code></pre></div>
<div class="cell-output cell-output-display">
<pre><code>&lt;transformers.pipelines.text_classification.TextClassificationPipeline&gt;</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb10" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">## showing the lookup's auto-complete</span></span>
<span id="cb10-2"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># classifier.</span></span></code></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb11" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">## viewing all of a class' methods and properties</span></span>
<span id="cb11-2"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">dir</span>(classifier)</span></code></pre></div>
<div class="cell-output cell-output-display">
<pre><code>['__abstractmethods__',
 '__call__',
 '__class__',
 '__delattr__',
 '__dict__',
 '__dir__',
 '__doc__',
 '__eq__',
 '__format__',
 '__ge__',
 '__getattribute__',
 '__getstate__',
 '__gt__',
 '__hash__',
 '__init__',
 '__init_subclass__',
 '__le__',
 '__lt__',
 '__module__',
 '__ne__',
 '__new__',
 '__reduce__',
 '__reduce_ex__',
 '__repr__',
 '__setattr__',
 '__sizeof__',
 '__slots__',
 '__str__',
 '__subclasshook__',
 '__weakref__',
 '_abc_impl',
 '_batch_size',
 '_ensure_tensor_on_device',
 '_forward',
 '_forward_params',
 '_num_workers',
 '_postprocess_params',
 '_preprocess_params',
 '_sanitize_parameters',
 'binary_output',
 'call_count',
 'check_model_type',
 'default_input_names',
 'device',
 'device_placement',
 'ensure_tensor_on_device',
 'feature_extractor',
 'forward',
 'framework',
 'function_to_apply',
 'get_inference_context',
 'get_iterator',
 'image_processor',
 'iterate',
 'model',
 'modelcard',
 'postprocess',
 'predict',
 'preprocess',
 'return_all_scores',
 'run_multi',
 'run_single',
 'save_pretrained',
 'task',
 'tokenizer',
 'torch_dtype',
 'transform']</code></pre>
</div>
</div>
<p>Jupyter notebooks have powerful ways of inspecting and analyzing the code, as we‚Äôre running it.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb13" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">## refresher</span></span>
<span id="cb13-2">classifier</span></code></pre></div>
<div class="cell-output cell-output-display">
<pre><code>&lt;transformers.pipelines.text_classification.TextClassificationPipeline&gt;</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb15" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">## the power of asking questions</span></span>
<span id="cb15-2"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># classifier? # help(classifier)</span></span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Signature:      classifier(*args, **kwargs)
Type:           TextClassificationPipeline
String form:    &lt;transformers.pipelines.text_classification.TextClassificationPipeline object&gt;
File:           ~/mambaforge/envs/llm_base/lib/python3.11/site-packages/transformers/pipelines/text_classification.py
Docstring:     
Text classification pipeline using any `ModelForSequenceClassification`. See the [sequence classification
examples](../task_summary#sequence-classification) for more information.

Example:

```python
&gt;&gt;&gt; from transformers import pipeline

&gt;&gt;&gt; classifier = pipeline(model="distilbert-base-uncased-finetuned-sst-2-english")
&gt;&gt;&gt; classifier("This movie is disgustingly good !")
[{'label': 'POSITIVE', 'score': 1.0}]

&gt;&gt;&gt; classifier("Director tried too much.")
[{'label': 'NEGATIVE', 'score': 0.996}]
```

Learn more about the basics of using a pipeline in the [pipeline tutorial](../pipeline_tutorial)

This text classification pipeline can currently be loaded from [`pipeline`] using the following task identifier:
`"sentiment-analysis"` (for classifying sequences according to positive or negative sentiments).

If multiple classification labels are available (`model.config.num_labels &gt;= 2`), the pipeline will run a softmax
over the results. If there is a single label, the pipeline will run a sigmoid over the result.

The models that this pipeline can use are models that have been fine-tuned on a sequence classification task. See
the up-to-date list of available models on
[huggingface.co/models](https://huggingface.co/models?filter=text-classification).

Arguments:
    model ([`PreTrainedModel`] or [`TFPreTrainedModel`]):
        The model that will be used by the pipeline to make predictions. This needs to be a model inheriting from
        [`PreTrainedModel`] for PyTorch and [`TFPreTrainedModel`] for TensorFlow.
    tokenizer ([`PreTrainedTokenizer`]):
        The tokenizer that will be used by the pipeline to encode data for the model. This object inherits from
        [`PreTrainedTokenizer`].
    modelcard (`str` or [`ModelCard`], *optional*):
        Model card attributed to the model for this pipeline.
    framework (`str`, *optional*):
        The framework to use, either `"pt"` for PyTorch or `"tf"` for TensorFlow. The specified framework must be
        installed.

        If no framework is specified, will default to the one currently installed. If no framework is specified and
        both frameworks are installed, will default to the framework of the `model`, or to PyTorch if no model is
        provided.
    task (`str`, defaults to `""`):
        A task-identifier for the pipeline.
    num_workers (`int`, *optional*, defaults to 8):
        When the pipeline will use *DataLoader* (when passing a dataset, on GPU for a Pytorch model), the number of
        workers to be used.
    batch_size (`int`, *optional*, defaults to 1):
        When the pipeline will use *DataLoader* (when passing a dataset, on GPU for a Pytorch model), the size of
        the batch to use, for inference this is not always beneficial, please read [Batching with
        pipelines](https://huggingface.co/transformers/main_classes/pipelines.html#pipeline-batching) .
    args_parser ([`~pipelines.ArgumentHandler`], *optional*):
        Reference to the object in charge of parsing supplied pipeline parameters.
    device (`int`, *optional*, defaults to -1):
        Device ordinal for CPU/GPU supports. Setting this to -1 will leverage CPU, a positive will run the model on
        the associated CUDA device id. You can pass native `torch.device` or a `str` too.
    binary_output (`bool`, *optional*, defaults to `False`):
        Flag indicating if the output the pipeline should happen in a binary format (i.e., pickle) or as raw text.

    return_all_scores (`bool`, *optional*, defaults to `False`):
        Whether to return all prediction scores or just the one of the predicted class.
    function_to_apply (`str`, *optional*, defaults to `"default"`):
        The function to apply to the model outputs in order to retrieve the scores. Accepts four different values:

        - `"default"`: if the model has a single label, will apply the sigmoid function on the output. If the model
          has several labels, will apply the softmax function on the output.
        - `"sigmoid"`: Applies the sigmoid function on the output.
        - `"softmax"`: Applies the softmax function on the output.
        - `"none"`: Does not apply any function on the output.
Call docstring:
Classify the text(s) given as inputs.

Args:
    args (`str` or `List[str]` or `Dict[str]`, or `List[Dict[str]]`):
        One or several texts to classify. In order to use text pairs for your classification, you can send a
        dictionary containing `{"text", "text_pair"}` keys, or a list of those.
    top_k (`int`, *optional*, defaults to `1`):
        How many results to return.
    function_to_apply (`str`, *optional*, defaults to `"default"`):
        The function to apply to the model outputs in order to retrieve the scores. Accepts four different
        values:

        If this argument is not specified, then it will apply the following functions according to the number
        of labels:

        - If the model has a single label, will apply the sigmoid function on the output.
        - If the model has several labels, will apply the softmax function on the output.

        Possible values are:

        - `"sigmoid"`: Applies the sigmoid function on the output.
        - `"softmax"`: Applies the softmax function on the output.
        - `"none"`: Does not apply any function on the output.

Return:
    A list or a list of list of `dict`: Each result comes as list of dictionaries with the following keys:

    - **label** (`str`) -- The label predicted.
    - **score** (`float`) -- The corresponding probability.

    If `top_k` is used, one such dictionary is returned per label.</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb17" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">## again, with feeling</span></span>
<span id="cb17-2"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># classifier?? # ?? shows you the source code of the object</span></span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Signature:      classifier(*args, **kwargs)
Type:           TextClassificationPipeline
String form:    &lt;transformers.pipelines.text_classification.TextClassificationPipeline object&gt;
File:           ~/mambaforge/envs/llm_base/lib/python3.11/site-packages/transformers/pipelines/text_classification.py
Source:        
@add_end_docstrings(
    PIPELINE_INIT_ARGS,
    r"""
        return_all_scores (`bool`, *optional*, defaults to `False`):
            Whether to return all prediction scores or just the one of the predicted class.
        function_to_apply (`str`, *optional*, defaults to `"default"`):
            The function to apply to the model outputs in order to retrieve the scores. Accepts four different values:

            - `"default"`: if the model has a single label, will apply the sigmoid function on the output. If the model
              has several labels, will apply the softmax function on the output.
            - `"sigmoid"`: Applies the sigmoid function on the output.
            - `"softmax"`: Applies the softmax function on the output.
            - `"none"`: Does not apply any function on the output.
    """,
)
class TextClassificationPipeline(Pipeline):
    """
    Text classification pipeline using any `ModelForSequenceClassification`. See the [sequence classification
    examples](../task_summary#sequence-classification) for more information.

    Example:

    ```python
    &gt;&gt;&gt; from transformers import pipeline

    &gt;&gt;&gt; classifier = pipeline(model="distilbert-base-uncased-finetuned-sst-2-english")
    &gt;&gt;&gt; classifier("This movie is disgustingly good !")
    [{'label': 'POSITIVE', 'score': 1.0}]

    &gt;&gt;&gt; classifier("Director tried too much.")
    [{'label': 'NEGATIVE', 'score': 0.996}]
    ```

    Learn more about the basics of using a pipeline in the [pipeline tutorial](../pipeline_tutorial)

    This text classification pipeline can currently be loaded from [`pipeline`] using the following task identifier:
    `"sentiment-analysis"` (for classifying sequences according to positive or negative sentiments).

    If multiple classification labels are available (`model.config.num_labels &gt;= 2`), the pipeline will run a softmax
    over the results. If there is a single label, the pipeline will run a sigmoid over the result.

    The models that this pipeline can use are models that have been fine-tuned on a sequence classification task. See
    the up-to-date list of available models on
    [huggingface.co/models](https://huggingface.co/models?filter=text-classification).
    """

    return_all_scores = False
    function_to_apply = ClassificationFunction.NONE

    def __init__(self, **kwargs):
        super().__init__(**kwargs)

        self.check_model_type(
            TF_MODEL_FOR_SEQUENCE_CLASSIFICATION_MAPPING_NAMES
            if self.framework == "tf"
            else MODEL_FOR_SEQUENCE_CLASSIFICATION_MAPPING_NAMES
        )

    def _sanitize_parameters(self, return_all_scores=None, function_to_apply=None, top_k="", **tokenizer_kwargs):
        # Using "" as default argument because we're going to use `top_k=None` in user code to declare
        # "No top_k"
        preprocess_params = tokenizer_kwargs

        postprocess_params = {}
        if hasattr(self.model.config, "return_all_scores") and return_all_scores is None:
            return_all_scores = self.model.config.return_all_scores

        if isinstance(top_k, int) or top_k is None:
            postprocess_params["top_k"] = top_k
            postprocess_params["_legacy"] = False
        elif return_all_scores is not None:
            warnings.warn(
                "`return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of"
                " `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.",
                UserWarning,
            )
            if return_all_scores:
                postprocess_params["top_k"] = None
            else:
                postprocess_params["top_k"] = 1

        if isinstance(function_to_apply, str):
            function_to_apply = ClassificationFunction[function_to_apply.upper()]

        if function_to_apply is not None:
            postprocess_params["function_to_apply"] = function_to_apply
        return preprocess_params, {}, postprocess_params

    def __call__(self, *args, **kwargs):
        """
        Classify the text(s) given as inputs.

        Args:
            args (`str` or `List[str]` or `Dict[str]`, or `List[Dict[str]]`):
                One or several texts to classify. In order to use text pairs for your classification, you can send a
                dictionary containing `{"text", "text_pair"}` keys, or a list of those.
            top_k (`int`, *optional*, defaults to `1`):
                How many results to return.
            function_to_apply (`str`, *optional*, defaults to `"default"`):
                The function to apply to the model outputs in order to retrieve the scores. Accepts four different
                values:

                If this argument is not specified, then it will apply the following functions according to the number
                of labels:

                - If the model has a single label, will apply the sigmoid function on the output.
                - If the model has several labels, will apply the softmax function on the output.

                Possible values are:

                - `"sigmoid"`: Applies the sigmoid function on the output.
                - `"softmax"`: Applies the softmax function on the output.
                - `"none"`: Does not apply any function on the output.

        Return:
            A list or a list of list of `dict`: Each result comes as list of dictionaries with the following keys:

            - **label** (`str`) -- The label predicted.
            - **score** (`float`) -- The corresponding probability.

            If `top_k` is used, one such dictionary is returned per label.
        """
        result = super().__call__(*args, **kwargs)
        # TODO try and retrieve it in a nicer way from _sanitize_parameters.
        _legacy = "top_k" not in kwargs
        if isinstance(args[0], str) and _legacy:
            # This pipeline is odd, and return a list when single item is run
            return [result]
        else:
            return result

    def preprocess(self, inputs, **tokenizer_kwargs) -&gt; Dict[str, GenericTensor]:
        return_tensors = self.framework
        if isinstance(inputs, dict):
            return self.tokenizer(**inputs, return_tensors=return_tensors, **tokenizer_kwargs)
        elif isinstance(inputs, list) and len(inputs) == 1 and isinstance(inputs[0], list) and len(inputs[0]) == 2:
            # It used to be valid to use a list of list of list for text pairs, keeping this path for BC
            return self.tokenizer(
                text=inputs[0][0], text_pair=inputs[0][1], return_tensors=return_tensors, **tokenizer_kwargs
            )
        elif isinstance(inputs, list):
            # This is likely an invalid usage of the pipeline attempting to pass text pairs.
            raise ValueError(
                "The pipeline received invalid inputs, if you are trying to send text pairs, you can try to send a"
                ' dictionary `{"text": "My text", "text_pair": "My pair"}` in order to send a text pair.'
            )
        return self.tokenizer(inputs, return_tensors=return_tensors, **tokenizer_kwargs)

    def _forward(self, model_inputs):
        # `XXXForSequenceClassification` models should not use `use_cache=True` even if it's supported
        model_forward = self.model.forward if self.framework == "pt" else self.model.call
        if "use_cache" in inspect.signature(model_forward).parameters.keys():
            model_inputs["use_cache"] = False
        return self.model(**model_inputs)

    def postprocess(self, model_outputs, function_to_apply=None, top_k=1, _legacy=True):
        # `_legacy` is used to determine if we're running the naked pipeline and in backward
        # compatibility mode, or if running the pipeline with `pipeline(..., top_k=1)` we're running
        # the more natural result containing the list.
        # Default value before `set_parameters`
        if function_to_apply is None:
            if self.model.config.problem_type == "multi_label_classification" or self.model.config.num_labels == 1:
                function_to_apply = ClassificationFunction.SIGMOID
            elif self.model.config.problem_type == "single_label_classification" or self.model.config.num_labels &gt; 1:
                function_to_apply = ClassificationFunction.SOFTMAX
            elif hasattr(self.model.config, "function_to_apply") and function_to_apply is None:
                function_to_apply = self.model.config.function_to_apply
            else:
                function_to_apply = ClassificationFunction.NONE

        outputs = model_outputs["logits"][0]
        outputs = outputs.numpy()

        if function_to_apply == ClassificationFunction.SIGMOID:
            scores = sigmoid(outputs)
        elif function_to_apply == ClassificationFunction.SOFTMAX:
            scores = softmax(outputs)
        elif function_to_apply == ClassificationFunction.NONE:
            scores = outputs
        else:
            raise ValueError(f"Unrecognized `function_to_apply` argument: {function_to_apply}")

        if top_k == 1 and _legacy:
            return {"label": self.model.config.id2label[scores.argmax().item()], "score": scores.max().item()}

        dict_scores = [
            {"label": self.model.config.id2label[i], "score": score.item()} for i, score in enumerate(scores)
        ]
        if not _legacy:
            dict_scores.sort(key=lambda x: x["score"], reverse=True)
            if top_k is not None:
                dict_scores = dict_scores[:top_k]
        return dict_scores
Call docstring:
Classify the text(s) given as inputs.

Args:
    args (`str` or `List[str]` or `Dict[str]`, or `List[Dict[str]]`):
        One or several texts to classify. In order to use text pairs for your classification, you can send a
        dictionary containing `{"text", "text_pair"}` keys, or a list of those.
    top_k (`int`, *optional*, defaults to `1`):
        How many results to return.
    function_to_apply (`str`, *optional*, defaults to `"default"`):
        The function to apply to the model outputs in order to retrieve the scores. Accepts four different
        values:

        If this argument is not specified, then it will apply the following functions according to the number
        of labels:

        - If the model has a single label, will apply the sigmoid function on the output.
        - If the model has several labels, will apply the softmax function on the output.

        Possible values are:

        - `"sigmoid"`: Applies the sigmoid function on the output.
        - `"softmax"`: Applies the softmax function on the output.
        - `"none"`: Does not apply any function on the output.

Return:
    A list or a list of list of `dict`: Each result comes as list of dictionaries with the following keys:

    - **label** (`str`) -- The label predicted.
    - **score** (`float`) -- The corresponding probability.

    If `top_k` is used, one such dictionary is returned per label.</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb19" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1">classifier.forward <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># what actually runs the inputs</span></span></code></pre></div>
<div class="cell-output cell-output-display">
<pre><code>&lt;bound method Pipeline.forward of &lt;transformers.pipelines.text_classification.TextClassificationPipeline object&gt;&gt;</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb21" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1">classifier.forward??</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Signature: classifier.forward(model_inputs, **forward_params)
Docstring: &lt;no docstring&gt;
Source:   
    def forward(self, model_inputs, **forward_params):
        with self.device_placement():
            if self.framework == "tf":
                model_inputs["training"] = False
                model_outputs = self._forward(model_inputs, **forward_params)
            elif self.framework == "pt":
                inference_context = self.get_inference_context()
                with inference_context():
                    model_inputs = self._ensure_tensor_on_device(model_inputs, device=self.device)
                    model_outputs = self._forward(model_inputs, **forward_params)
                    model_outputs = self._ensure_tensor_on_device(model_outputs, device=torch.device("cpu"))
            else:
                raise ValueError(f"Framework {self.framework} is not supported")
        return model_outputs
File:      ~/mambaforge/envs/llm_base/lib/python3.11/site-packages/transformers/pipelines/base.py
Type:      method</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb23" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1">classifier._forward??</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Signature: classifier._forward(model_inputs)
Docstring:
_forward will receive the prepared dictionary from `preprocess` and run it on the model. This method might
involve the GPU or the CPU and should be agnostic to it. Isolating this function is the reason for `preprocess`
and `postprocess` to exist, so that the hot path, this method generally can run as fast as possible.

It is not meant to be called directly, `forward` is preferred. It is basically the same but contains additional
code surrounding `_forward` making sure tensors and models are on the same device, disabling the training part
of the code (leading to faster inference).
Source:   
    def _forward(self, model_inputs):
        # `XXXForSequenceClassification` models should not use `use_cache=True` even if it's supported
        model_forward = self.model.forward if self.framework == "pt" else self.model.call
        if "use_cache" in inspect.signature(model_forward).parameters.keys():
            model_inputs["use_cache"] = False
        return self.model(**model_inputs)
File:      ~/mambaforge/envs/llm_base/lib/python3.11/site-packages/transformers/pipelines/text_classification.py
Type:      method</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb25" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1">classifier.model</span></code></pre></div>
<div class="cell-output cell-output-display">
<pre><code>DistilBertForSequenceClassification(
  (distilbert): DistilBertModel(
    (embeddings): Embeddings(
      (word_embeddings): Embedding(30522, 768, padding_idx=0)
      (position_embeddings): Embedding(512, 768)
      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer): Transformer(
      (layer): ModuleList(
        (0-5): 6 x TransformerBlock(
          (attention): MultiHeadSelfAttention(
            (dropout): Dropout(p=0.1, inplace=False)
            (q_lin): Linear(in_features=768, out_features=768, bias=True)
            (k_lin): Linear(in_features=768, out_features=768, bias=True)
            (v_lin): Linear(in_features=768, out_features=768, bias=True)
            (out_lin): Linear(in_features=768, out_features=768, bias=True)
          )
          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (ffn): FFN(
            (dropout): Dropout(p=0.1, inplace=False)
            (lin1): Linear(in_features=768, out_features=3072, bias=True)
            (lin2): Linear(in_features=3072, out_features=768, bias=True)
            (activation): GELUActivation()
          )
          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
        )
      )
    )
  )
  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)
  (classifier): Linear(in_features=768, out_features=2, bias=True)
  (dropout): Dropout(p=0.2, inplace=False)
)</code></pre>
</div>
</div>
<blockquote class="blockquote">
<p>Summary: <code>?</code> and <code>??</code> are very powerful and useful inspection tools for Jupyter notebooks.</p>
</blockquote>
</section>
<section id="peeking-inside-the-pipeline" class="level1">
<h1>Peeking inside the <code>pipeline</code></h1>
<p>We can see the pipeline loaded the model.</p>
<p>It then handled the three key pieces (Config, Preprocess, Model) underneath the hood. What exactly is <code>pipeline</code> doing?</p>
<p>Let‚Äôs build or own pipeline from scratch, stepping one small level below the abstraction. To do this, we will create each of the key pieces manually.</p>
<section id="config-class" class="level3">
<h3 class="anchored" data-anchor-id="config-class">Config class</h3>
<div class="cell">
<div class="sourceCode cell-code" id="cb27" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> transformers <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> DistilBertConfig</span></code></pre></div>
</div>
</section>
<section id="preprocessor-class" class="level3">
<h3 class="anchored" data-anchor-id="preprocessor-class">Preprocessor class</h3>
<div class="cell">
<div class="sourceCode cell-code" id="cb28" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> transformers <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> DistilBertTokenizer</span></code></pre></div>
</div>
</section>
<section id="model-class" class="level3">
<h3 class="anchored" data-anchor-id="model-class">Model class</h3>
<div class="cell">
<div class="sourceCode cell-code" id="cb29" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># from transformers import DistilBertModel</span></span>
<span id="cb29-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> transformers <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> DistilBertForSequenceClassification</span></code></pre></div>
</div>
<p>Now we can use the model‚Äôs name from up above and build each piece ourselves. HuggingFace uses the <code>from_pretrained</code> method to make this quick and easy.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb30" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb30-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># the model we are using</span></span>
<span id="cb30-2">model_name <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'distilbert-base-uncased-finetuned-sst-2-english'</span></span></code></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb31" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># creating the config</span></span>
<span id="cb31-2">config <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> DistilBertConfig.from_pretrained(model_name)</span>
<span id="cb31-3"></span>
<span id="cb31-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># creating the preprocessor </span></span>
<span id="cb31-5">tokenizer <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> DistilBertTokenizer.from_pretrained(model_name)</span>
<span id="cb31-6"></span>
<span id="cb31-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># creating the model</span></span>
<span id="cb31-8">model <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> DistilBertForSequenceClassification.from_pretrained(model_name)</span></code></pre></div>
</div>
<p>Next we build a simple pipeline with these manual pieces.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb32" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb32-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> preprocess(text: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">str</span>):</span>
<span id="cb32-2">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""</span></span>
<span id="cb32-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Sends `text` through the LLM's tokenizer.  </span></span>
<span id="cb32-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    The tokenizers turns words and characters into special inputs for the LLM.</span></span>
<span id="cb32-5"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    """</span></span>
<span id="cb32-6">    tokenized_inputs <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> tokenizer(text, return_tensors<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'pt'</span>)</span>
<span id="cb32-7">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> tokenized_inputs</span></code></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb33" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb33-1">text <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"I love Fractal! I'm so glad it's not a cult!"</span></span>
<span id="cb33-2">preprocess(text)</span></code></pre></div>
<div class="cell-output cell-output-display">
<pre><code>{'input_ids': tensor([[  101,  1045,  2293, 25312, 25572,  2140,   999,  1045,  1005,  1049,
          2061,  5580,  2009,  1005,  1055,  2025,  1037,  8754,   999,   102]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb35" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb35-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> forward(text):</span>
<span id="cb35-2">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""</span></span>
<span id="cb35-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    First we preprocess the `text` into tokens.</span></span>
<span id="cb35-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Then we send the `token_inputs` to the model.</span></span>
<span id="cb35-5"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    """</span></span>
<span id="cb35-6">    token_inputs <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> preprocess(text)</span>
<span id="cb35-7">    outputs <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> model(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">**</span>token_inputs)</span>
<span id="cb35-8">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> outputs</span></code></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb36" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb36-1">outputs <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> forward(text)<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">;</span> outputs</span></code></pre></div>
<div class="cell-output cell-output-display">
<pre><code>SequenceClassifierOutput(loss=None, logits=tensor([[-3.3825,  3.5515]], grad_fn=&lt;AddmmBackward0&gt;), hidden_states=None, attentions=None)</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb38" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb38-1">config.id2label[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>]</span></code></pre></div>
<div class="cell-output cell-output-display">
<pre><code>'POSITIVE'</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb40" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb40-1">outputs.logits</span></code></pre></div>
<div class="cell-output cell-output-display">
<pre><code>tensor([[-3.3825,  3.5515]], grad_fn=&lt;AddmmBackward0&gt;)</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb42" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb42-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> count_parameters(model):</span>
<span id="cb42-2">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">sum</span>(p.numel() <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> p <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> model.parameters() <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> p.requires_grad)</span></code></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb43" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb43-1"><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>count_parameters(model)<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:,}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span></span></code></pre></div>
<div class="cell-output cell-output-display">
<pre><code>'66,955,010'</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb45" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb45-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> process_outputs(outs):</span>
<span id="cb45-2">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""</span></span>
<span id="cb45-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Here is where HuggingFace does the most for us via `pipeline`.  </span></span>
<span id="cb45-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    """</span></span>
<span id="cb45-5">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># grab the raw "scores" that from the model for Positive and Negative labels</span></span>
<span id="cb45-6">    logits <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> outs.logits</span>
<span id="cb45-7"></span>
<span id="cb45-8">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># find the strongest label score, aka the model's decision</span></span>
<span id="cb45-9">    pred_idx <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> logits.argmax(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>).item()</span>
<span id="cb45-10"></span>
<span id="cb45-11">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># use the `config` object to find the class label</span></span>
<span id="cb45-12">    pred_label <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> config.id2label[pred_idx]  </span>
<span id="cb45-13"></span>
<span id="cb45-14">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># calculate the human-readable number for the score</span></span>
<span id="cb45-15">    pred_score <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> logits.softmax(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)[:, pred_idx].item()</span>
<span id="cb45-16"></span>
<span id="cb45-17">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> {</span>
<span id="cb45-18">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'label'</span>: pred_label,</span>
<span id="cb45-19">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'score'</span>: pred_score, </span>
<span id="cb45-20">    }</span></code></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb46" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb46-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> simple_pipeline(text):</span>
<span id="cb46-2">    model_outs <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> forward(text)</span>
<span id="cb46-3">    preds <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> process_outputs(model_outs)</span>
<span id="cb46-4">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> preds</span></code></pre></div>
</div>
<p>Let‚Äôs call this pipeline on the same example text from before.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb47" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb47-1">text <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"We are very happy to show you the ü§ó Transformers library."</span></span></code></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb48" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb48-1">simple_pipeline(text)</span></code></pre></div>
<div class="cell-output cell-output-display">
<pre><code>{'label': 'POSITIVE', 'score': 0.9997795224189758}</code></pre>
</div>
</div>
</section>
</section>
<section id="more-hf-magic" class="level1">
<h1>More HF magic</h1>
<p><code>Auto</code> classes.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb50" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb50-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> transformers <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> AutoConfig</span>
<span id="cb50-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> transformers <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> AutoTokenizer</span>
<span id="cb50-3"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> transformers <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> AutoModelForSequenceClassification</span></code></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb51" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb51-1">model_name <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"finiteautomata/bertweet-base-sentiment-analysis"</span></span></code></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb52" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb52-1">config <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> AutoConfig.from_pretrained(model_name)</span>
<span id="cb52-2">tokenizer <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> AutoTokenizer.from_pretrained(model_name)</span>
<span id="cb52-3">model <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> AutoModelForSequenceClassification.from_pretrained(model_name)</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Downloading (‚Ä¶)lve/main/config.json: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 949/949 [00:00&lt;00:00, 3.91MB/s]
Downloading (‚Ä¶)okenizer_config.json: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 338/338 [00:00&lt;00:00, 1.30MB/s]
Downloading (‚Ä¶)solve/main/vocab.txt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 843k/843k [00:00&lt;00:00, 5.35MB/s]
Downloading (‚Ä¶)solve/main/bpe.codes: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1.08M/1.08M [00:00&lt;00:00, 17.1MB/s]
Downloading (‚Ä¶)in/added_tokens.json: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 22.0/22.0 [00:00&lt;00:00, 103kB/s]
Downloading (‚Ä¶)cial_tokens_map.json: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 167/167 [00:00&lt;00:00, 717kB/s]
emoji is not installed, thus not converting emoticons or emojis into text. Install emoji: pip3 install emoji==0.6.0
Downloading pytorch_model.bin: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 540M/540M [00:30&lt;00:00, 17.6MB/s] </code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb54" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb54-1">simple_pipeline(text)</span></code></pre></div>
<div class="cell-output cell-output-display">
<pre><code>{'label': 'POS', 'score': 0.9929807186126709}</code></pre>
</div>
</div>


</section>

 ]]></description>
  <guid>https://enzokro.github.io/sample_blog_2/blog/posts/2023-09-24-Second-Post/index.html</guid>
  <pubDate>Wed, 27 Sep 2023 23:19:41 GMT</pubDate>
</item>
</channel>
</rss>
