{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"`nbdev` for Blogging and Building Python Libraries\"\n",
    "author: \"Chris Kroenke\"\n",
    "date: \"9/27/2022\"\n",
    "toc: true \n",
    "badges: true\n",
    "categories: [fractal, python, nbdev]\n",
    "image: nbdev_pic.png\n",
    "jupyter: python3\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goals:  \n",
    "\n",
    "This notebook has two goals:  \n",
    "- Create a blog and publish a post.  \n",
    "- Build a small, dynamic python library for a HuggingFace Sentiment Analysis pipeline. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intro:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the [`nbdev`](https://nbdev.fast.ai/) library for both tasks. `nbdev` is a powerful tool inspired by two main ideas:  \n",
    "- [Literate Programming](https://en.wikipedia.org/wiki/Literate_programming).  \n",
    "- [Exploratory Programming](https://en.wikipedia.org/wiki/Exploratory_programming).   \n",
    "\n",
    "The next section briefly covers these ideas and why their combination is so powerful.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Literate Programming \n",
    "\n",
    "In Literate Programming, text descriptions are woven directly into a project's source code. This is different from most codebases where documentation exists in a separate set of files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code, tests, and documentation are all first-class citizens in Literate Programming. For example in `nbdev` a Notebook is the unified source of all three things. Instead of having to independently manage code, docs, and tests, everything happens in the Notebook. If the Notebook runs then you know your code will run. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tight loop between what you're doing (the code), describing what you're doing (the documentation), and making sure it's correct (tests) is a great approach for both research and thinking in general.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Programming  \n",
    "\n",
    "Exploratory Programming is an open-ended approach for tackling new problems and unknown domains. It's very helpful at the start of a project while its scope or requirements are being finalized.   \n",
    "\n",
    "The dynamic, interactive nature of Notebooks is ideal for Exploratory Programming. It makes the barrier to try new things extremely low. And it's fun! Jupyter also has many more advanced tools to inspect code and debug its outputs. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining Literate and Exploratory Programming  \n",
    "\n",
    "`nbdev`'s main workflow combines these two ideas. It's a great approach for trying things out, figuring out what they do, and how they work. We can poke around and explore codebases in a much more interactive way than usual. Iterations are fast and cheap so it's easy to follow any hit of curiosity. And if anything breaks, we can always restart the Notebook and try again.\n",
    "\n",
    "These ideas can be mix and matched as on the fly. For example at the start of a project, while figuring out the problem space, we might lean Exploratory. Then, as the idea matures, we pivot more Literate to refine and crystallize our approach.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for the first goal: creating and publishing a blog post."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Turning Notebooks into Blog Posts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, a high-level summary of how the blog will be created and published with `nbdev`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### High-Level Steps:  \n",
    "1. Create a new `nbdev` project.  \n",
    "2. Set it up to be a publishable blog.  \n",
    "3. Build and published the blog to Github pages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`nbdev` leverages a tool called [Quarto](https://quarto.org/) for blogging. Quarto is a publishing framework tailored for scientific and technical articles and posts. In a way it's a blogging platform for Literate Programming, where a series of code commands tells a story and takes the reader on a journey. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](quarto.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a new `nbdev` project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`nbdev` works on top of a Git repo, so the first step is creating a new, empty repository. There is a [handy Github link](https://github.com/new) that takes us straight to the page for creating new repos. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Note: We need a completely empty repo. Don't include a `.gitignore` or `README.md`.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example the empty repo is called `sample_blog`, but feel free to call it anything you'd like. We're not tied to this name either. We can always create new repos with different, better names. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now clone the empty new repo to your computer. Make sure to change the github link below so it points to your repo instead. \n",
    "\n",
    "```bash\n",
    "# clone the repo to your computer\n",
    "git clone https://github.com/enzokro/sample_blog.git # <-- ! link with your repo here\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can go into this repo and let `nbdev` work its initialization magic. Run the `nbdev_new` command to get started. It will prompt you for some general info like a short description about the project.  \n",
    "\n",
    "```bash\n",
    "# move into the new repo and initialize the nbdev project\n",
    "cd sample_blog/\n",
    "nbdev_new\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of the options and configs for the project are in the `settings.ini` file. `nbdev` looks in this file when it needs information about the project. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After `nbdev_new` finishes, you will have a brand new `nbdev` project!  \n",
    "\n",
    "Run a `git status` command to see everything that was added. Then we commit and push these changes to Github."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "# add, commit, and push the files created by nbdev\n",
    "git add .\n",
    "git commit -m'Initial nbdev project creation'\n",
    "git push\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we mentioned earlier, `nbdev` leverages Quarto for publishing Notebooks. Let's take a look at how create this project into a proper Quarto blog."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding Quarto to the Mix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start by activating the virtual environment:\n",
    "\n",
    "```bash\n",
    "# activate the environment\n",
    "mamba activate llm_base\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then install Quarto via `nbdev` by running the `nbdev_install_quarto` command. Note the command will ask for admin privileges.\n",
    "\n",
    "```bash\n",
    "# install quarto\n",
    "nbdev_install_quarto\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may need to refresh the terminal session before it can find the `quarto` commands. To be safe, open up a new terminal and re-activate the environment. Now the command below will check if Quarto was installed successfully.  \n",
    "\n",
    "```bash\n",
    "# shows us where quarto was installed\n",
    "which quarto \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Turning an `nbdev` project into a Quarto blog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a typical `nbdev` project the Notebooks all live inside of the `nbs/` folder. There are the Notebooks that eventually become a project's documentation, tests, and source code.   \n",
    "\n",
    "For Quarto to instead publish Notebooks as blog posts, we need to add a few files and folders to the `nbs/` folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is what the blog-ready `nbs/` folder should look like to start. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Initial Structure for Quarto Blog**:\n",
    "```\n",
    "sample_blog\n",
    "â””â”€â”€â”€nbs/\n",
    "â”‚   â”‚   _quarto.yml\n",
    "â”‚   â”‚   index.ipynb\n",
    "â”‚   â””â”€â”€â”€blog/\n",
    "â”‚       â”‚   index.qmd\n",
    "â”‚       â””â”€â”€â”€posts/\n",
    "â”‚           â””â”€â”€â”€2023-09-27-Blog-Intro/     \n",
    "â”‚               â”‚   index.ipynb\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main change we are making is adding a `blog/` folder inside of the `nbs/` directory. Inside we place an `index.qmd` file at the top-level that tells Quarto about our blog. For example, here's an `index.qmd` file that describes our blog and how its posts should be listed:\n",
    "\n",
    "```yaml\n",
    "---\n",
    "title: Example Blog\n",
    "subtitle: Publishing with Quarto and nbdev\n",
    "listing:\n",
    "  sort: \"date desc\"\n",
    "  contents: \"posts\"\n",
    "  sort-ui: false\n",
    "  filter-ui: false\n",
    "  categories: true\n",
    "  feed: true\n",
    "page-layout: full\n",
    "---\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each post gets its own folder with an `index.ipynb` Notebook inside that has the actual post's content. We can also add photos, videos, and any other media that enhances the post inside of the folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, we are going a bit meta and using this Notebook itself as `index.ipynb` in the folder called `2023-09-27-Blog-Intro/`.  \n",
    "\n",
    "In other words this Notebook will also be our first blog post."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hosting the Blog on Github Pages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will build and host our site on Github's [Pages platform](https://pages.github.com/) for free. The screenshot below shows the settings we need for the repo to be published as a blog. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](github_pages.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Specifically, we need to set `Deploy from a branch` under the `Build and deployment section`, and pick the `gh-pages` branch. `gh-pages` is a special branch where Quarto parses our Notebooks into a proper website. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And that's all there is to it! [Click here](https://enzokro.github.io/sample_blog_2/blog/posts/2023-09-27-Blog-Intro/) for a live link to this Notebook as a blog post. We've now completed the first task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating python libraries with `nbdev`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will build a small, dynamic python library. The library itself is a thin wrapper around a HuggingFace Sentiment Analysis pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`nbdev` has a set of commands that turn Notebooks into complete python libraries.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These helper commands are called *directives* and usually go at the start of a code cell. They start with the special string `#|`, which is similar to the shebang string `#!` you may have seen in other scripts. These directive tell `nbdev` how to parse the code cell and what to do with it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, the `default_exp` directive tells `nbdev` how to name the output python file. Here we use it to name this specific python file as `lesson_2/simple_pipeline.py`: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp lesson_2.simple_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've named our soon-to-be python file we can implement the actual pipeline. The `export` directive in a code cell tells `nbdev` to parse and extract the code inside."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cck/mambaforge/envs/llm_base/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#| export \n",
    "# imports the pieces for the pipeline\n",
    "from transformers import AutoConfig\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForSequenceClassification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> A small annoyance: `import` statements have to be in their own code cell. We can't pair them with function calls like `print()`, for example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we refactor the code from the previous notebook (`01_first_run.ipynb`) into a simple class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class SentimentPipeline:\n",
    "    def __init__(self, model_name):\n",
    "        \"\"\"\n",
    "        Sentiment Analysis pipeline.\n",
    "        \"\"\"\n",
    "        self.model_name = model_name\n",
    "        self.config = AutoConfig.from_pretrained(self.model_name)\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(self.model_name)\n",
    "        self.model = AutoModelForSequenceClassification.from_pretrained(self.model_name)\n",
    "\n",
    "\n",
    "    def preprocess(self, text: str):\n",
    "        \"\"\"\n",
    "        Sends `text` through the LLM's tokenizer.  \n",
    "        The tokenizer turns words and characters into special inputs for the LLM.\n",
    "        \"\"\"\n",
    "        tokenized_inputs = self.tokenizer(text, return_tensors='pt')\n",
    "        return tokenized_inputs\n",
    "    \n",
    "\n",
    "    def forward(self, text: str):\n",
    "        \"\"\"\n",
    "        First we preprocess the `text` into tokens.\n",
    "        Then we send the `token_inputs` to the model.\n",
    "        \"\"\"\n",
    "        token_inputs = self.preprocess(text)\n",
    "        outputs = self.model(**token_inputs)\n",
    "        return outputs\n",
    "    \n",
    "\n",
    "    def process_outputs(self, outs):\n",
    "        \"\"\"\n",
    "        Here we mimic the post-processing that HuggingFace automatically does in its `pipeline`.  \n",
    "        \"\"\"\n",
    "        # grab the raw scores from the model for Positive and Negative labels\n",
    "        logits = outs.logits\n",
    "\n",
    "        # find the strongest label score, aka the model's decision\n",
    "        pred_idx = logits.argmax(1).item()\n",
    "\n",
    "        # use the `config` object to find the actual class label\n",
    "        pred_label = self.config.id2label[pred_idx]  \n",
    "\n",
    "        # calculate the human-readable probability score for this class\n",
    "        pred_score = logits.softmax(-1)[:, pred_idx].item()\n",
    "\n",
    "        # return the predicted label and its score\n",
    "        return {\n",
    "            'label': pred_label,\n",
    "            'score': pred_score, \n",
    "        }\n",
    "    \n",
    "\n",
    "    def __call__(self, text: str):\n",
    "        \"\"\"\n",
    "        Overriding the call method to easily and intuitively call the pipeline.\n",
    "        \"\"\"\n",
    "        model_outs = self.forward(text)\n",
    "        preds = self.process_outputs(model_outs)\n",
    "        return preds\n",
    "\n",
    "    \n",
    "    def __repr__(self):\n",
    "        \"\"\"\n",
    "        Cleaner representation of the pipeline.\n",
    "        \"\"\"\n",
    "        return f\"SentimentAnalysis_{self.model_name}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now make sure that `SentimentPipeline` actually works, since live tests are one of the main benefits of Notebook coding! Note that since we don't put an `|# export` directive in the cell below, it won't be part of the exported python file either.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing the pipeline\n",
    "\n",
    "from Fractal_LLM_Course.lesson_2.simple_pipeline import SentimentPipeline\n",
    "\n",
    "# loading the default model\n",
    "model_name = 'distilbert-base-uncased-finetuned-sst-2-english'\n",
    "classifier = SentimentPipeline(model_name) \n",
    "\n",
    "# make sure that the official HuggingFace example works as expected\n",
    "results = classifier(\"We are very happy to show you the ðŸ¤— Transformers library.\"); results\n",
    "assert results['label'] == 'POSITIVE'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can think of the cell above as a unit test for the `SentimentAnalysis` pipeline. `nbdev` runs this notebook when it compiles the library, and if the tests fail then the build fails. This is a great, built-in way of making sure that the library works as expected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exporting the library  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now export the library using the `nbdev_build_lib` command. This will create a file inside of the top-level library folder `Fractal_LLM_Course`. Per the `default_exp` directive, the file will called  `lesson_2/simple_pipeline.py`.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "> Note: we can add nested library directories with the typical python dot (`.`) syntax. For example, if we'd instead used the directive `|# default_exp simple_pipeline`, then the file would live at the top-level library folder: `Fractal_LLM_Course/simple_pipeline.py`. Adding the `lesson_2.` created the `lesson_2/` folder for us."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following set of commands will:  \n",
    "- Export the Notebooks into a library.   \n",
    "- Install an editable version of the library.   \n",
    "- Import the newly installed library in a python shell.   \n",
    "\n",
    "Make sure to run them from the top-level directory of the repo. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "# export Notebooks into a library\n",
    "nbdev_export_lib  \n",
    "\n",
    "# install the library as an editable install\n",
    "pip install -e . \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now open up a python shell to import and use the library. \n",
    "\n",
    "```python\n",
    "# import the newly installed library \n",
    "from Fractal_LLM_Course.lesson_2.simple_pipeline import SentimentPipeline\n",
    "\n",
    "# use our custom SentimentAnalysis pipeline!\n",
    "model_name = 'distilbert-base-uncased-finetuned-sst-2-english'\n",
    "classifier = SentimentPipeline(model_name) \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congrats! We've now built and installed a full, working python library. This is just the start, `nbdev` has many other advanced tools you can [read about here](https://nbdev.fast.ai/tutorials/tutorial.html#advanced-functionality)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Notebook covered two key features of `nbdev`:  \n",
    "- Creating a blog.  \n",
    "- Building a python library.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both of these features are great for research and development. We can quickly try new ideas and easily share them with others."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- [Official nbdev tutorial.](https://nbdev.fast.ai/tutorials/tutorial.html#installation)\n",
    "- [Blogging with nbdev.](https://nbdev.fast.ai/tutorials/blogging.html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
